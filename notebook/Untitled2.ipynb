{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import namedtuple\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/home/angrypark/korean-text-matching-tf/\")\n",
    "\n",
    "from utils.utils import JamoProcessor\n",
    "from text.tokenizers import SentencePieceTokenizer\n",
    "\n",
    "Config = namedtuple(\"config\", [\"sent_piece_model\"])\n",
    "config = Config(\"/media/scatter/scatterdisk/tokenizer/sent_piece.100K.model\")\n",
    "processor = JamoProcessor()\n",
    "tokenizer = SentencePieceTokenizer(config)\n",
    "\n",
    "def my_word_tokenizer(raw, pos=[\"Noun\", \"Alpha\", \"Verb\", \"Number\"], stopword=[]):\n",
    "    return [word for word in tokenizer.tokenize(raw)]\n",
    "\n",
    "def my_char_tokenizer(raw, pos=[\"Noun\", \"Alpha\", \"Verb\", \"Number\"], stopword=[]):\n",
    "    return [processor.word_to_jamo(word) for word in tokenizer.tokenize(raw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained embedding loaded. Number of OOV : 5272 / 90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/scatter/scatterdisk/reply_matching_model/runs/delstm_1024_nsrandom4_lr1e-3/best_loss/best_loss.ckpt\n"
     ]
    }
   ],
   "source": [
    "from feature_extractor import FeatureExtractor\n",
    "feature_extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_submission(model, name):\n",
    "    def load_data():\n",
    "        base_dir = \"/home/angrypark/paraphrase_detection/data/origin_data/\"\n",
    "        train_set = pd.read_csv(base_dir + \"train_set.csv\")\n",
    "        val_set = pd.read_csv(base_dir + \"val_set.csv\")\n",
    "        test_set = pd.read_csv(base_dir + \"test_set.csv\")\n",
    "        with open(base_dir + \"train.txt\", \"r\") as f:\n",
    "            _, _, train_labels = zip(*[line.strip().split(\"\\t\") for line in f if line])\n",
    "            train_labels = [1 if l==\"1\" else 0 for l in train_labels]\n",
    "        with open(base_dir + \"val.txt\", \"r\") as f:\n",
    "            _, _, val_labels = zip(*[line.strip().split(\"\\t\") for line in f if line]) \n",
    "            val_labels = [1 if l==\"1\" else 0 for l in val_labels]\n",
    "        with open(base_dir + \"test.txt\", \"r\") as f:\n",
    "            _, _, test_labels = zip(*[line.strip().split(\"\\t\") for line in f if line])\n",
    "            test_labels = [1 if l==\"1\" else 0 for l in test_labels]\n",
    "            \n",
    "        return train_set, val_set, test_set, train_labels, val_labels, test_labels\n",
    "    \n",
    "    with open(\"/home/angrypark/paraphrase_detection/data/test_queries.txt\", \"r\") as f:\n",
    "        _, queries = zip(*[line.strip().split(\"\\t\") for line in f])\n",
    "        \n",
    "    with open(\"/home/angrypark/paraphrase_detection/data/test_replies.txt\", \"r\") as f:\n",
    "        reply_to_idx_dict = dict()\n",
    "        replies = list()\n",
    "        for line in f:\n",
    "            splits = line.strip().split(\"\\t\")\n",
    "            reply_to_idx_dict[splits[1]] = splits[0]\n",
    "            replies.append(splits[1])\n",
    "    \n",
    "    train_set, val_set, test_set, train_labels, val_labels, test_labels = load_data()\n",
    "    print(\"Train accuracy : {:.8f}\".format(model.score(train_set, train_labels)))\n",
    "    print(\"Val   accuracy : {:.8f}\".format(model.score(val_set, val_labels)))\n",
    "    print(\"Test  accuracy : {:.8f}\".format(model.score(test_set, test_labels)))\n",
    "    \n",
    "    length = len(replies)\n",
    "    submit_set = pd.read_csv(\"../data/submit_set_update.csv\")\n",
    "    features = list(submit_set.columns).copy()\n",
    "    features.remove(\"sentence_A\")\n",
    "    features.remove(\"sentence_B\")\n",
    "    \n",
    "    predictions = list()\n",
    "    for i, query in enumerate(queries):\n",
    "        data = submit_set.iloc[i*length:(i+1)*length]\n",
    "        probs = [p[1] for p in model.predict_proba(data[features]).tolist()]\n",
    "        scores = [(reply, score) for reply, score in zip(replies, probs)]\n",
    "        predict = sorted(scores, key=lambda x: x[1], reverse=True)[0][0]\n",
    "        predictions.append(reply_to_idx_dict[predict])\n",
    "    submission = pd.read_csv(\"../submission/sample_submission.csv\")\n",
    "    submission[\"id_script\"] = pd.Series(predictions)\n",
    "    submission.to_csv(\"../submission/{}.csv\".format(name), index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pure/train.txt\", \"r\") as f:\n",
    "    train_A, train_B, labels = zip(*[line.strip().split(\"\\t\") for line in f])\n",
    "    train_labels = [1 if l==\"1\" else 0 for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pure/val.txt\", \"r\") as f:\n",
    "    val_A, val_B, labels = zip(*[line.strip().split(\"\\t\") for line in f])\n",
    "    val_labels = [1 if l==\"1\" else 0 for l in labels]\n",
    "    \n",
    "with open(\"../data/pure/test.txt\", \"r\") as f:\n",
    "    test_A, test_B, labels = zip(*[line.strip().split(\"\\t\") for line in f])\n",
    "    test_labels = [1 if l==\"1\" else 0 for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 48s, sys: 16.8 s, total: 8min 5s\n",
      "Wall time: 7min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_set = pd.DataFrame(feature_extractor.extract_features(train_A, train_B))\n",
    "train_set.to_csv(\"../data/pure/train_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 2.8 s, total: 1min 10s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_set = pd.DataFrame(feature_extractor.extract_features(val_A, val_B))\n",
    "val_set.to_csv(\"../data/pure/val_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.3 s, sys: 1.4 s, total: 43.7 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_set = pd.DataFrame(feature_extractor.extract_features(test_A, test_B))\n",
    "test_set.to_csv(\"../data/pure/test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([pd.read_csv(\"../data/pure/train_set.csv\"), pd.read_csv(\"../data/pure/val_set.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = train_labels + val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pure + train&val + tfidf update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(total, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.85066667\n",
      "Val   accuracy : 0.73891881\n",
      "Test  accuracy : 0.73543016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000it [02:17, 874.83it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb, name=\"xgb_pure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pure + train + tfidf word update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.84969000\n",
      "Val   accuracy : 0.73632974\n",
      "Test  accuracy : 0.73846967\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb, name=\"xgb_pure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "어제 1등한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.85188855\n",
      "Val   accuracy : 0.74361713\n",
      "Test  accuracy : 0.72810643\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb_old, name=\"xgb_old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "내가 개난리 치면서 라벨링 해서 추가했지만 성능은 더 나빠진 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.85182910\n",
      "Val   accuracy : 0.74295596\n",
      "Test  accuracy : 0.72746060\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb, name=\"xgb_new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "방금 그대로 다시 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.85096333\n",
      "Val   accuracy : 0.73990265\n",
      "Test  accuracy : 0.72327210\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb, name=\"xgb_old_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"../data/small/train_set.csv\")\n",
    "val_set = pd.read_csv(\"../data/small/val_set.csv\")\n",
    "test_set = pd.read_csv(\"../data/small/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sim = list()\n",
    "for a, b in zip(train_A, train_B):\n",
    "    word_sim.append(cosine_similarity(feature_extractor.tfidf_word_vectorizer.transform([a]), \n",
    "                                      feature_extractor.tfidf_word_vectorizer.transform([b]))[0][0])\n",
    "train_set[\"tfidf_word_sim\"] = pd.Series(word_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sim = list()\n",
    "for a, b in zip(val_A, val_B):\n",
    "    word_sim.append(cosine_similarity(feature_extractor.tfidf_word_vectorizer.transform([a]), \n",
    "                                      feature_extractor.tfidf_word_vectorizer.transform([b]))[0][0])\n",
    "val_set[\"tfidf_word_sim\"] = pd.Series(word_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sim = list()\n",
    "for a, b in zip(test_A, test_B):\n",
    "    word_sim.append(cosine_similarity(feature_extractor.tfidf_word_vectorizer.transform([a]), \n",
    "                                      feature_extractor.tfidf_word_vectorizer.transform([b]))[0][0])\n",
    "test_set[\"tfidf_word_sim\"] = pd.Series(word_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([train_set, val_set])\n",
    "total_labels = pd.Series(train_labels + val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf word vectorizer 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(total, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 0.85105631\n",
      "Val   : 0.74173533\n",
      "Test  : 0.72487729\n"
     ]
    }
   ],
   "source": [
    "print(\"Train : {:.8f}\".format(xgb.score(train_set, train_labels)))\n",
    "print(\"Val   : {:.8f}\".format(xgb.score(val_set, val_labels)))\n",
    "print(\"Test  : {:.8f}\".format(xgb.score(test_set, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "train set에만 학습한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 0.85142950\n",
      "Val   : 0.73354694\n",
      "Test  : 0.72287523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print(\"Train : {:.8f}\".format(xgb.score(train_set, train_labels)))\n",
    "print(\"Val   : {:.8f}\".format(xgb.score(val_set, val_labels)))\n",
    "print(\"Test  : {:.8f}\".format(xgb.score(test_set, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.85019667\n",
      "Val   accuracy : 0.73845278\n",
      "Test  accuracy : 0.72089335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000it [02:21, 847.83it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb, name=\"xgb_word_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(\"../data/small/train_set.csv\", index=False)\n",
    "val_set.to_csv(\"../data/small/val_set.csv\", index=False)\n",
    "test_set.to_csv(\"../data/small/test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2 = pd.read_csv(\"../data/small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cb = CatBoostClassifier()\n",
    "cb.fit(train_set, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
