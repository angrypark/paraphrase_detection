{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import namedtuple\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/home/angrypark/korean-text-matching-tf/\")\n",
    "\n",
    "from utils.utils import JamoProcessor\n",
    "from text.tokenizers import SentencePieceTokenizer\n",
    "\n",
    "Config = namedtuple(\"config\", [\"sent_piece_model\"])\n",
    "config = Config(\"/media/scatter/scatterdisk/tokenizer/sent_piece.100K.model\")\n",
    "processor = JamoProcessor()\n",
    "tokenizer = SentencePieceTokenizer(config)\n",
    "\n",
    "def my_word_tokenizer(raw, pos=[\"Noun\", \"Alpha\", \"Verb\", \"Number\"], stopword=[]):\n",
    "    return [word for word in tokenizer.tokenize(raw)]\n",
    "\n",
    "def my_char_tokenizer(raw, pos=[\"Noun\", \"Alpha\", \"Verb\", \"Number\"], stopword=[]):\n",
    "    return [processor.word_to_jamo(word) for word in tokenizer.tokenize(raw)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained embedding loaded. Number of OOV : 5272 / 90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/scatter/scatterdisk/reply_matching_model/runs/delstm_1024_nsrandom4_lr1e-3/best_loss/best_loss.ckpt\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/angrypark/paraphrase_detection/data/test_queries.txt\", \"r\") as f:\n",
    "    _, queries = zip(*[line.strip().split(\"\\t\") for line in f])\n",
    "\n",
    "with open(\"/home/angrypark/paraphrase_detection/data/test_replies.txt\", \"r\") as f:\n",
    "    reply_to_idx_dict = dict()\n",
    "    replies = list()\n",
    "    for line in f:\n",
    "        if not line:\n",
    "            continue\n",
    "        splits = line.strip().split(\"\\t\")\n",
    "        reply_to_idx_dict[splits[1]] = splits[0]\n",
    "        replies.append(splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = {}\n",
    "length = len(replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('너 도대체 정체가 뭔데?',\n",
       " '넌 어떻게 만들어졌니?',\n",
       " '나 결혼 할 수 있을까요?',\n",
       " '이제 점심먹을거야',\n",
       " '오늘도 나 꿈꿨다',\n",
       " '오늘 먹은 고기 진짜 맛있었음',\n",
       " '비 엄청온다 ㄷㄷ')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[23:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab_probs</th>\n",
       "      <th>ba_probs</th>\n",
       "      <th>edit_distance</th>\n",
       "      <th>semantic_sim</th>\n",
       "      <th>substring_ratio</th>\n",
       "      <th>tfidf_char_sim</th>\n",
       "      <th>tfidf_word_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.860981</td>\n",
       "      <td>0.790133</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.690985</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.343242</td>\n",
       "      <td>0.119655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935994</td>\n",
       "      <td>0.974954</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.781252</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.754234</td>\n",
       "      <td>0.422782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.993880</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.704285</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.322436</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515418</td>\n",
       "      <td>0.149820</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.557047</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.032540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.999118</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.887023</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.683980</td>\n",
       "      <td>0.252547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ab_probs  ba_probs  edit_distance  semantic_sim  substring_ratio  \\\n",
       "0  0.860981  0.790133       0.565217      0.690985         0.173913   \n",
       "1  0.935994  0.974954       0.428571      0.781252         0.357143   \n",
       "2  0.998473  0.993880       0.680000      0.704285         0.240000   \n",
       "3  0.515418  0.149820       0.847826      0.557047         0.043478   \n",
       "4  0.999465  0.999118       0.250000      0.887023         0.583333   \n",
       "\n",
       "   tfidf_char_sim  tfidf_word_sim  \n",
       "0        0.343242        0.119655  \n",
       "1        0.754234        0.422782  \n",
       "2        0.322436        0.000000  \n",
       "3        0.032540        0.000000  \n",
       "4        0.683980        0.252547  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/my_data/train_set.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [06:06<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "total = pd.DataFrame()\n",
    "for query in tqdm(queries):\n",
    "    A, B = [query]*length, replies\n",
    "    extracted = feature_extractor.extract_features(A, B)\n",
    "    extracted = pd.DataFrame(extracted)\n",
    "    extracted[\"sentence_A\"] = query\n",
    "    extracted[\"sentence_B\"] = pd.Series(replies)\n",
    "    total = pd.concat([total, extracted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = [\"사랑해요\"] * length, replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sim = list()\n",
    "for a, b in zip(A, B):\n",
    "    word_sim.append(cosine_similarity(feature_extractor.tfidf_word_vectorizer.transform([a]), \n",
    "                                      feature_extractor.tfidf_word_vectorizer.transform([b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('사랑해요', '흑흑 일 많은데 졸리다')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(a, b) for a, b in zip(A, B)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x91743 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.tfidf_word_vectorizer.transform(['사랑해요'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = feature_extractor.extract_features(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted[\"tfidf_word_sim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_submission(model, name):\n",
    "    def load_data():\n",
    "        base_dir = \"/home/angrypark/paraphrase_detection/data/my_data/\"\n",
    "        train_set = pd.read_csv(base_dir + \"train_set.csv\")\n",
    "        val_set = pd.read_csv(base_dir + \"val_set.csv\")\n",
    "        test_set = pd.read_csv(base_dir + \"test_set.csv\")\n",
    "        with open(base_dir + \"train.txt\", \"r\") as f:\n",
    "            _, _, train_labels = zip(*[line.strip().split(\"\\t\") for line in f if line])\n",
    "            train_labels = [1 if l==\"1\" else 0 for l in train_labels]\n",
    "        with open(base_dir + \"val.txt\", \"r\") as f:\n",
    "            _, _, val_labels = zip(*[line.strip().split(\"\\t\") for line in f if line]) \n",
    "            val_labels = [1 if l==\"1\" else 0 for l in val_labels]\n",
    "        with open(base_dir + \"test.txt\", \"r\") as f:\n",
    "            _, _, test_labels = zip(*[line.strip().split(\"\\t\") for line in f if line])\n",
    "            test_labels = [1 if l==\"1\" else 0 for l in test_labels]\n",
    "            \n",
    "        return train_set, val_set, test_set, train_labels, val_labels, test_labels\n",
    "    \n",
    "    with open(\"/home/angrypark/paraphrase_detection/data/test_queries.txt\", \"r\") as f:\n",
    "        _, queries = zip(*[line.strip().split(\"\\t\") for line in f])\n",
    "        \n",
    "    with open(\"/home/angrypark/paraphrase_detection/data/test_replies.txt\", \"r\") as f:\n",
    "        reply_to_idx_dict = dict()\n",
    "        replies = list()\n",
    "        for line in f:\n",
    "            splits = line.strip().split(\"\\t\")\n",
    "            reply_to_idx_dict[splits[1]] = splits[0]\n",
    "            replies.append(splits[1])\n",
    "    \n",
    "    train_set, val_set, test_set, train_labels, val_labels, test_labels = load_data()\n",
    "    print(\"Train accuracy : {:.5f}\".format(model.score(train_set, train_labels)))\n",
    "    print(\"Val   accuracy : {:.5f}\".format(model.score(val_set, val_labels)))\n",
    "    print(\"Test  accuracy : {:.5f}\".format(model.score(test_set, test_labels)))\n",
    "    \n",
    "    length = len(replies)\n",
    "    submit_set = pd.read_csv(\"../data/submit_set.csv\")\n",
    "    features = list(submit_set.columns).copy()\n",
    "    features.remove(\"sentence_A\")\n",
    "    features.remove(\"sentence_B\")\n",
    "    \n",
    "    predictions = list()\n",
    "    for i, query in enumerate(queries):\n",
    "        data = submit_set.iloc[i*length:(i+1)*length]\n",
    "        probs = [p[1] for p in model.predict_proba(data[features]).tolist()]\n",
    "        scores = [(reply, score) for reply, score in zip(replies, probs)]\n",
    "        predict = sorted(scores, key=lambda x: x[1], reverse=True)[0][0]\n",
    "        predictions.append(reply_to_idx_dict[predict])\n",
    "    submission = pd.read_csv(\"../submission/sample_submission.csv\")\n",
    "    submission[\"id_script\"] = pd.Series(predictions)\n",
    "    submission.to_csv(\"../submission/{}.csv\".format(name), index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_new = pickle.load(open(\"../models/new_xgb.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.88728\n",
      "Val   accuracy : 0.73200\n",
      "Test  accuracy : 0.76550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "_ = model_to_submission(xgb_new, name=\"xgb_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_old = pickle.load(open(\"../models/xgb.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.88795\n",
      "Val   accuracy : 0.74307\n",
      "Test  accuracy : 0.77395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb_submission = model_to_submission(xgb_old, name=\"xgb_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_query</th>\n",
       "      <th>id_script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>570</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>572</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>573</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>574</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>575</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>576</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>577</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>578</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>579</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>580</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>581</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>582</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>584</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>586</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>587</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>588</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>590</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>591</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>593</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>594</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>596</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>597</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>598</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_query id_script\n",
       "0           0       152\n",
       "1           1        29\n",
       "2           2        26\n",
       "3           3       168\n",
       "4           4        40\n",
       "5           5        31\n",
       "6           6       164\n",
       "7           7       149\n",
       "8           8        67\n",
       "9           9        24\n",
       "10         10        36\n",
       "11         11        45\n",
       "12         12       169\n",
       "13         13        31\n",
       "14         14        29\n",
       "15         15       112\n",
       "16         16       164\n",
       "17         17        14\n",
       "18         18       168\n",
       "19         19       116\n",
       "20         20        73\n",
       "21         21        16\n",
       "22         22        95\n",
       "23         23        73\n",
       "24         24        31\n",
       "25         25        45\n",
       "26         26       155\n",
       "27         27       189\n",
       "28         28       117\n",
       "29         29        26\n",
       "..        ...       ...\n",
       "570       570        30\n",
       "571       571        45\n",
       "572       572        56\n",
       "573       573        26\n",
       "574       574       147\n",
       "575       575       148\n",
       "576       576         5\n",
       "577       577       163\n",
       "578       578        28\n",
       "579       579        94\n",
       "580       580        75\n",
       "581       581        25\n",
       "582       582       178\n",
       "583       583         5\n",
       "584       584       102\n",
       "585       585       116\n",
       "586       586        94\n",
       "587       587        73\n",
       "588       588        30\n",
       "589       589        14\n",
       "590       590        73\n",
       "591       591        36\n",
       "592       592        76\n",
       "593       593       178\n",
       "594       594        56\n",
       "595       595       156\n",
       "596       596       118\n",
       "597       597        36\n",
       "598       598       109\n",
       "599       599        39\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(probs, name):\n",
    "    \"\"\"probs를 집어넣으면 바로 submission 파일 생성\n",
    "    :param probs: {query: [(reply, score), (reply, score)...]} 형태\n",
    "    :param name: submission의 이름\n",
    "    \"\"\"\n",
    "    with open(\"/home/angrypark/paraphrase_detection/data/test_replies.txt\", \"r\") as f:\n",
    "        reply_to_idx_dict = {reply: idx for idx, reply in [line.strip().split(\"\\t\") for line in f]}\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angryenv",
   "language": "python",
   "name": "angryenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
