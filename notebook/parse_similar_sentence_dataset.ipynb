{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse similar sentence dataset\n",
    "- 구글 스프레드시트에서 정리한 simialr sentence 데이터셋을 파싱해서 정리한다\n",
    "- Requirements\n",
    "    - `seed_queries.tsv`: seed 쿼리들 정리해놓은 시트의 tsv\n",
    "    - `pair_labelings.tsv`: candidate pair들 모아서 정리해놓은 시트의 tsv\n",
    "    - `manual_pair_labelings.tsv`: 매뉴얼하게 pair들 만들어놓은 시트의 tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15134\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/small/test.txt\", \"r\") as f:\n",
    "    print(sum([1 for line in f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/angrypark/paraphrase_detection/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import JamoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = JamoProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval(processor.word_to_jamo(\"그랍시당\"), processor.word_to_jamo(\"노란색만\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [{\"a\": 1, \"b\": 2, \"c\": 4}, {\"a\": 1, \"b\": 2, \"c\": 3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  4\n",
       "1  1  2  3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processor.word_to_jamo(\"그랍시당\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_seed_queries(seed_query_path):\n",
    "    '''\n",
    "    seed query tsv를 파싱함.\n",
    "    홀수째 row와 짝수째 row가 존댓말 관계이므로, 둘이 1 관계라고 생각하고 이를 파싱한다\n",
    "    '''\n",
    "    relations = []\n",
    "    with open(seed_query_path) as f:\n",
    "        for line in f.readlines()[1:]:  # first row is header\n",
    "            splits = line.split('\\t')\n",
    "            for sent1, sent2 in zip(splits[::2], splits[1::2]):\n",
    "                if len(sent1.strip()) > 0 and len(sent2.strip()) > 0:\n",
    "                    relations.append((sent1.strip(), sent2.strip(), '1'))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나이가 어떻게 돼?', '나이가 어떻게 되세요?', '1'),\n",
       " ('갈까?', '갈까요?', '1'),\n",
       " ('우리 집에서 라면 먹고 갈래?', '저희 집에서 라면 먹고 가실래요?', '1'),\n",
       " ('별로 안 짜증나', '별로 안 짜증나요', '1'),\n",
       " ('너 몇살이야?', '몇살이세요?', '1'),\n",
       " ('잘잤어?', '잘잤어요?', '1'),\n",
       " ('고양이 귀엽지 나도 좋아해', '고양이 귀엽죠 저도 좋아해요', '1'),\n",
       " ('나 안 바빠', '저 안 바빠요', '1'),\n",
       " ('너는 누구야?', '당신은 누구세요?', '1'),\n",
       " ('뭐해?', '뭐해요?', '1')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_seed_queries('dataset/seed_queries.tsv')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def parse_pair_labelings(pair_labeling_path):\n",
    "    '''\n",
    "    pair labeling 된 걸 파싱함.\n",
    "    tsv 파일이고 (Query, Candidate, Label) 로 되어있다고 생각하자\n",
    "    '''\n",
    "    relations = []\n",
    "    with open(pair_labeling_path) as tsvfile:\n",
    "        reader = csv.DictReader(tsvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            # pass empty labels\n",
    "            label = row['Label'].strip()\n",
    "            if len(label) > 0 and label not in {'?', '.'}:\n",
    "                relations.append((row['Query'], row['Candidate'], label))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('너 몇살이야?', '몇살?', '1'),\n",
       " ('너 몇살이야?', '몇쨜?', '1'),\n",
       " ('잘가', '잘가염', '1'),\n",
       " ('잘가', '잘가시죠', '1'),\n",
       " ('잘가', '빨리 가', '0'),\n",
       " ('잘가', '잘까', '0'),\n",
       " ('잘가', '잘까요?', '0'),\n",
       " ('잘가', '잘갔어?', '0'),\n",
       " ('잘가', '잘 도착했어?', '0'),\n",
       " ('안녕?', '안녕이라고 말하지마', '0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_pair_labelings('dataset/manual_pair_labelings.tsv')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9566"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_relations = \\\n",
    "    parse_seed_queries('dataset/seed_queries.tsv') \\\n",
    "    + parse_pair_labelings('dataset/pair_labelings.tsv') \\\n",
    "    + parse_pair_labelings('dataset/manual_pair_labelings.tsv')\n",
    "    \n",
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A union-find disjoint set data structure.\n",
    "\"\"\"\n",
    "\n",
    "# 2to3 sanity\n",
    "from __future__ import (\n",
    "    absolute_import, division, print_function, unicode_literals,\n",
    ")\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class UnionFind(object):\n",
    "    \"\"\"Union-find disjoint sets datastructure.\n",
    "    Union-find is a data structure that maintains disjoint set\n",
    "    (called connected components or components in short) membership,\n",
    "    and makes it easier to merge (union) two components, and to find\n",
    "    if two elements are connected (i.e., belong to the same\n",
    "    component).\n",
    "    This implements the \"weighted-quick-union-with-path-compression\"\n",
    "    union-find algorithm.  Only works if elements are immutable\n",
    "    objects.\n",
    "    Worst case for union and find: :math:`(N + M \\log^* N)`, with\n",
    "    :math:`N` elements and :math:`M` unions. The function\n",
    "    :math:`\\log^*` is the number of times needed to take :math:`\\log`\n",
    "    of a number until reaching 1. In practice, the amortized cost of\n",
    "    each operation is nearly linear [1]_.\n",
    "    Terms\n",
    "    -----\n",
    "    Component\n",
    "        Elements belonging to the same disjoint set\n",
    "    Connected\n",
    "        Two elements are connected if they belong to the same component.\n",
    "    Union\n",
    "        The operation where two components are merged into one.\n",
    "    Root\n",
    "        An internal representative of a disjoint set.\n",
    "    Find\n",
    "        The operation to find the root of a disjoint set.\n",
    "    Parameters\n",
    "    ----------\n",
    "    elements : NoneType or container, optional, default: None\n",
    "        The initial list of elements.\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_elts : int\n",
    "        Number of elements.\n",
    "    n_comps : int\n",
    "        Number of distjoint sets or components.\n",
    "    Implements\n",
    "    ----------\n",
    "    __len__\n",
    "        Calling ``len(uf)`` (where ``uf`` is an instance of ``UnionFind``)\n",
    "        returns the number of elements.\n",
    "    __contains__\n",
    "        For ``uf`` an instance of ``UnionFind`` and ``x`` an immutable object,\n",
    "        ``x in uf`` returns ``True`` if ``x`` is an element in ``uf``.\n",
    "    __getitem__\n",
    "        For ``uf`` an instance of ``UnionFind`` and ``i`` an integer,\n",
    "        ``res = uf[i]`` returns the element stored in the ``i``-th index.\n",
    "        If ``i`` is not a valid index an ``IndexError`` is raised.\n",
    "    __setitem__\n",
    "        For ``uf`` and instance of ``UnionFind``, ``i`` an integer and ``x``\n",
    "        an immutable object, ``uf[i] = x`` changes the element stored at the\n",
    "        ``i``-th index. If ``i`` is not a valid index an ``IndexError`` is\n",
    "        raised.\n",
    "    .. [1] http://algs4.cs.princeton.edu/lectures/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, elements=None):\n",
    "        self.n_elts = 0  # current num of elements\n",
    "        self.n_comps = 0  # the number of disjoint sets or components\n",
    "        self._next = 0  # next available id\n",
    "        self._elts = []  # the elements\n",
    "        self._indx = {}  #  dict mapping elt -> index in _elts\n",
    "        self._par = []  # parent: for the internal tree structure\n",
    "        self._siz = []  # size of the component - correct only for roots\n",
    "\n",
    "        if elements is None:\n",
    "            elements = []\n",
    "        for elt in elements:\n",
    "            self.add(elt)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return  (\n",
    "            '<UnionFind:\\n\\telts={},\\n\\tsiz={},\\n\\tpar={},\\nn_elts={},n_comps={}>'\n",
    "            .format(\n",
    "                self._elts,\n",
    "                self._siz,\n",
    "                self._par,\n",
    "                self.n_elts,\n",
    "                self.n_comps,\n",
    "            ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_elts\n",
    "\n",
    "    def __contains__(self, x):\n",
    "        return x in self._indx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < 0 or index >= self._next:\n",
    "            raise IndexError('index {} is out of bound'.format(index))\n",
    "        return self._elts[index]\n",
    "\n",
    "    def __setitem__(self, index, x):\n",
    "        if index < 0 or index >= self._next:\n",
    "            raise IndexError('index {} is out of bound'.format(index))\n",
    "        self._elts[index] = x\n",
    "\n",
    "    def add(self, x):\n",
    "        \"\"\"Add a single disjoint element.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : immutable object\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if x in self:\n",
    "            return\n",
    "        self._elts.append(x)\n",
    "        self._indx[x] = self._next\n",
    "        self._par.append(self._next)\n",
    "        self._siz.append(1)\n",
    "        self._next += 1\n",
    "        self.n_elts += 1\n",
    "        self.n_comps += 1\n",
    "\n",
    "    def find(self, x):\n",
    "        \"\"\"Find the root of the disjoint set containing the given element.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : immutable object\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The (index of the) root.\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If the given element is not found.\n",
    "        \"\"\"\n",
    "        if x not in self._indx:\n",
    "            raise ValueError('{} is not an element'.format(x))\n",
    "\n",
    "        p = self._indx[x]\n",
    "        while p != self._par[p]:\n",
    "            # path compression\n",
    "            q = self._par[p]\n",
    "            self._par[p] = self._par[q]\n",
    "            p = q\n",
    "        return p\n",
    "\n",
    "    def connected(self, x, y):\n",
    "        \"\"\"Return whether the two given elements belong to the same component.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : immutable object\n",
    "        y : immutable object\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if x and y are connected, false otherwise.\n",
    "        \"\"\"\n",
    "        return self.find(x) == self.find(y)\n",
    "\n",
    "    def union(self, x, y):\n",
    "        \"\"\"Merge the components of the two given elements into one.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : immutable object\n",
    "        y : immutable object\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Initialize if they are not already in the collection\n",
    "        for elt in [x, y]:\n",
    "            if elt not in self:\n",
    "                self.add(elt)\n",
    "\n",
    "        xroot = self.find(x)\n",
    "        yroot = self.find(y)\n",
    "        if xroot == yroot:\n",
    "            return\n",
    "        if self._siz[xroot] < self._siz[yroot]:\n",
    "            self._par[xroot] = yroot\n",
    "            self._siz[yroot] += self._siz[xroot]\n",
    "        else:\n",
    "            self._par[yroot] = xroot\n",
    "            self._siz[xroot] += self._siz[yroot]\n",
    "        self.n_comps -= 1\n",
    "\n",
    "    def component(self, x):\n",
    "        \"\"\"Find the connected component containing the given element.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : immutable object\n",
    "        Returns\n",
    "        -------\n",
    "        set\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            If the given element is not found.\n",
    "        \"\"\"\n",
    "        if x not in self:\n",
    "            raise ValueError('{} is not an element'.format(x))\n",
    "        elts = np.array(self._elts)\n",
    "        vfind = np.vectorize(self.find)\n",
    "        roots = vfind(elts)\n",
    "        return set(elts[roots == self.find(x)])\n",
    "\n",
    "    def components(self):\n",
    "        \"\"\"Return the list of connected components.\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of sets.\n",
    "        \"\"\"\n",
    "        elts = np.array(self._elts)\n",
    "        vfind = np.vectorize(self.find)\n",
    "        roots = vfind(elts)\n",
    "        distinct_roots = set(roots)\n",
    "        return [set(elts[roots == root]) for root in distinct_roots]\n",
    "        # comps = []\n",
    "        # for root in distinct_roots:\n",
    "        #     mask = (roots == root)\n",
    "        #     comp = set(elts[mask])\n",
    "        #     comps.append(comp)\n",
    "        # return comps\n",
    "\n",
    "    def component_mapping(self):\n",
    "        \"\"\"Return a dict mapping elements to their components.\n",
    "        The returned dict has the following semantics:\n",
    "            `elt -> component containing elt`\n",
    "        If x, y belong to the same component, the comp(x) and comp(y)\n",
    "        are the same objects (i.e., share the same reference). Changing\n",
    "        comp(x) will reflect in comp(y).  This is done to reduce\n",
    "        memory.\n",
    "        But this behaviour should not be relied on.  There may be\n",
    "        inconsitency arising from such assumptions or lack thereof.\n",
    "        If you want to do any operation on these sets, use caution.\n",
    "        For example, instead of\n",
    "        ::\n",
    "            s = uf.component_mapping()[item]\n",
    "            s.add(stuff)\n",
    "            # This will have side effect in other sets\n",
    "        do\n",
    "        ::\n",
    "            s = set(uf.component_mapping()[item]) # or\n",
    "            s = uf.component_mapping()[item].copy()\n",
    "            s.add(stuff)\n",
    "        or\n",
    "        ::\n",
    "            s = uf.component_mapping()[item]\n",
    "            s = s | {stuff}  # Now s is different\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dict with the semantics: `elt -> component contianing elt`.\n",
    "        \"\"\"\n",
    "        elts = np.array(self._elts)\n",
    "        vfind = np.vectorize(self.find)\n",
    "        roots = vfind(elts)\n",
    "        distinct_roots = set(roots)\n",
    "        comps = {}\n",
    "        for root in distinct_roots:\n",
    "            mask = (roots == root)\n",
    "            comp = set(elts[mask])\n",
    "            comps.update({x: comp for x in comp})\n",
    "            # Change ^this^, if you want a different behaviour:\n",
    "            # If you don't want to share the same set to different keys:\n",
    "            # comps.update({x: set(comp) for x in comp})\n",
    "        return comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9508\n"
     ]
    }
   ],
   "source": [
    "def create_node_set_from_relations(relations):\n",
    "    unique_strings = set()\n",
    "    for s1, s2, _ in relations:\n",
    "        unique_strings.add(s1)\n",
    "        unique_strings.add(s2)\n",
    "    unique_strings = list(unique_strings)\n",
    "    print(len(unique_strings))\n",
    "    \n",
    "    uf = UnionFind(unique_strings)\n",
    "    for s1, s2, r in relations:\n",
    "        if r == '1':\n",
    "            uf.union(s1, s2)\n",
    "        \n",
    "    return uf\n",
    "\n",
    "uf = create_node_set_from_relations(all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def mine_all_relations(relations, union_find):\n",
    "    '''\n",
    "    relation과 node set으로부터 가능한 모든 pair labeling들을 만들어낸다\n",
    "    만들 수 있는 케이스들은\n",
    "    (1) node set 내의 string들끼리 묶은 것 nP2개\n",
    "    (2) <나 >에서 한쪽 string을 node set의 것으로 치환한 것 2(n1 n2)개\n",
    "    (3) 0 relation에서 한쪽만 node set의 것으로 치환한것 2(n1+n2)개\n",
    "    '''\n",
    "    def neg_r(r):\n",
    "        assert r in {'<', '>'}\n",
    "        return '>' if r == '<' else '<'\n",
    "    \n",
    "    all_relation_set = set()\n",
    "    \n",
    "    # 일단 node set들을 돌며 nP2개를 만들자\n",
    "    node_sets = union_find.components()\n",
    "    for nodes in node_sets:\n",
    "        for n1, n2 in permutations(nodes, 2):\n",
    "            all_relation_set.add((n1, n2, '1'))\n",
    "    \n",
    "    # 이제 relation들을 돌며 케이스들에 맞게 add하자\n",
    "    node_set_mappings = uf.component_mapping()\n",
    "    for string1, string2, r in relations:\n",
    "        # '>' 이나 '<' 인 경우\n",
    "        if r in {'>', '<'}:\n",
    "            for n1 in node_set_mappings[string1]:\n",
    "                for n2 in node_set_mappings[string2]:\n",
    "                    all_relation_set.add((n1, n2, r))\n",
    "                    all_relation_set.add((n2, n1, neg_r(r)))\n",
    "        # '0' 인 경우\n",
    "        elif r == '0':\n",
    "            for n1 in node_set_mappings[string1]:\n",
    "                all_relation_set.add((n1, string2, '0'))\n",
    "                all_relation_set.add((string2, n1, '0'))\n",
    "            for n2 in node_set_mappings[string2]:\n",
    "                all_relation_set.add((string1, n2, '0'))\n",
    "                all_relation_set.add((n2, string1, '0'))\n",
    "                \n",
    "    return all_relation_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relation_set = mine_all_relations(all_relations, uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is double relation\n",
    "from collections import defaultdict\n",
    "pair_relations = defaultdict(list)\n",
    "\n",
    "for s1, s2, r in all_relation_set:\n",
    "    pair_relations[s1, s2].append(r)\n",
    "pair_relations = dict(pair_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 217004})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(len(x) for x in pair_relations.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all relation set을 돌면서 node set 사이의 interaction 유무를 보고, 그걸로 forest를 만들어보자\n",
    "nodes = set()\n",
    "edges = {}\n",
    "\n",
    "for s1, s2, r in all_relation_set:\n",
    "    s1_node_set_idx = uf.find(s1)\n",
    "    s2_node_set_idx = uf.find(s2)\n",
    "    nodes.add(s1_node_set_idx)\n",
    "    nodes.add(s2_node_set_idx)\n",
    "    \n",
    "    edges[s1_node_set_idx, s2_node_set_idx] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_set_idxs = sorted(list(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_set_uf = UnionFind(node_set_idxs)\n",
    "for n1, n2 in edges.keys():\n",
    "    node_set_uf.union(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_set_uf.components())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 230개의 forest가 생긴다.\n",
    "# 이걸 베이스로 random하게 forest들을 train/val/test (8:1:1) 로 split하고, 이걸로 pair들을 split하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(3091)\n",
    "\n",
    "node_set_idx_to_tvt = {}\n",
    "for components in node_set_uf.components():\n",
    "    random_value = random.random()\n",
    "    if random_value < 0.8:\n",
    "        tvt = 'train'\n",
    "    elif random_value < 0.9:\n",
    "        tvt = 'val'\n",
    "    else:\n",
    "        tvt = 'test'\n",
    "        \n",
    "    for c in components:\n",
    "        node_set_idx_to_tvt[c] = tvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {\n",
    "    'train': list(),\n",
    "    'val': list(),\n",
    "    'test': list()\n",
    "}\n",
    "\n",
    "for s1, s2, r in all_relation_set:\n",
    "    s1_node_set_idx = uf.find(s1)\n",
    "    s2_node_set_idx = uf.find(s2)\n",
    "    assert node_set_idx_to_tvt[s1_node_set_idx] == node_set_idx_to_tvt[s2_node_set_idx]\n",
    "    \n",
    "    tvt = node_set_idx_to_tvt[s1_node_set_idx]\n",
    "    pairs[tvt].append((s1, s2, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 15134, 'train': 182558, 'val': 19312}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: len(v) for k, v in pairs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 train set에서 원활한 학습을 위해 random negative들을 만들자.\n",
    "# train set에 있는 string 2개를 random하게 sampling해서 random negative 들을 만들것.\n",
    "train_random_negatives = []\n",
    "number_of_negatives_to_generate = 300000 - len(pairs['train'])\n",
    "\n",
    "train_strings = set()\n",
    "for s1, s2, r in pairs['train']:\n",
    "    train_strings.add(s1)\n",
    "    train_strings.add(s2)\n",
    "train_strings = sorted(list(train_strings))\n",
    "\n",
    "continue_count = 0\n",
    "while len(train_random_negatives) < number_of_negatives_to_generate:\n",
    "    string1 = random.choice(train_strings)\n",
    "    string2 = random.choice(train_strings)\n",
    "    \n",
    "    string1_nodeset = uf.find(string1)\n",
    "    string2_nodeset = uf.find(string2)\n",
    "    \n",
    "    # node set이 같거나, 기존에 interaction이 있으면 pass\n",
    "    if string1_nodeset == string2_nodeset:\n",
    "        continue\n",
    "    if (string1_nodeset, string2_nodeset) in edges or (string2_nodeset, string1_nodeset) in edges:\n",
    "        continue_count += 1\n",
    "        continue\n",
    "        \n",
    "    train_random_negatives.append((string1, string2, '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('헤헤 헹', '취미 있으신가요?', '0'),\n",
       " ('나 왔어 왔어', '비 왔었어', '0'),\n",
       " ('흐 다행이네요', '툭툭', '0'),\n",
       " ('일어나서 밥 먹음', '드시러 오실래여?', '0'),\n",
       " ('벌써 한시반이네요', '웅 지웠어요', '0'),\n",
       " ('큭 머하고이써?', '축하 해', '0'),\n",
       " ('추리닝만으로 확실합니까?', '어떻게 갔다 드려요?', '0'),\n",
       " ('내 얘기좀 해', '어 화났어?', '0'),\n",
       " ('이제 자러 간다', '근데 이렇게 연락하게 되네요', '0'),\n",
       " ('비가 한방울씩 떨어지네요', '말도 안되는 소리 하지 말아요', '0'),\n",
       " ('질문해줘요', '왜 자꾸 거짓말해?', '0'),\n",
       " ('흐헝 아니요', '외로운게 아니고', '0'),\n",
       " ('받고싶은거 없어요?', '내물음에 대답좀 해주세요', '0'),\n",
       " ('한 눈치 하나봐요?', '예리이고 싶네', '0'),\n",
       " ('너는 무슨 음악좋아해?', '오늘 영화보러 갈거양', '0'),\n",
       " ('지금 바쁘냐?', '축 축하해', '0'),\n",
       " ('언제나 치킨은 맛있어요', '장난입니다?', '0'),\n",
       " ('오늘은 원치않은 외출들이었어요', '뭐하구 있어요?', '0'),\n",
       " ('아프지 마라', '주로 어떤 노래 부르세여?', '0'),\n",
       " ('와 대박', '그 그래라', '0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_random_negatives[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs['train'].extend(train_random_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pair_to_txt(pair_list, path):\n",
    "    with open(path, 'w') as f:\n",
    "        for s1, s2, r in pair_list:\n",
    "            f.write('{}\\t{}\\t{}\\n'.format(s1, s2, r))\n",
    "            \n",
    "import os\n",
    "base_dir = '/home/shuuki4/sandbox_project/similar_sentence/simsent_data'\n",
    "\n",
    "write_pair_to_txt(\n",
    "    pairs['train'], os.path.join(base_dir, 'train.txt'))\n",
    "write_pair_to_txt(\n",
    "    pairs['val'], os.path.join(base_dir, 'val.txt'))\n",
    "write_pair_to_txt(\n",
    "    pairs['test'], os.path.join(base_dir, 'test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angryenv",
   "language": "python",
   "name": "angryenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
